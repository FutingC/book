{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory and Performance\n",
    "\n",
    "This section will cover memory layout in numpy arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with an example - summing up rows or columns of an array.  The computational complexity of each function is exactly the same: $n^2$ additions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2000\n",
    "x = np.random.rand(n, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.09 µs ± 103 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit x[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.55 µs ± 402 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit x[:,0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note there is a noticable difference in how long it takes the loop to run.  Summing over rows is faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x, order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.71 µs ± 258 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit x[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.25 µs ± 107 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit x[:,0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now summing over columns is faster.\n",
    "\n",
    "Why did this `order` flag matter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physical Memory\n",
    "\n",
    "There are several places you may have data stored on your computer:\n",
    "1. Hard Drive/SSD O(TB)\n",
    "2. Random Access Memory O(10GB)\n",
    "3. L3 Cache O(10MB)\n",
    "4. L2 Cache O(100KB)\n",
    "5. L1 Cache O(64KB)\n",
    "6. CPU (registers)\n",
    "\n",
    "At the top of the list, we have a lot of storage, but it takes longer to access data (in terms of clock cycles).\n",
    "As we go down the list, the amount of available storage decreases, but we are able to access data much faster.\n",
    "We can access CPU registers in 1 clock cycle, but we can only hold a small number (e.g. 8) 64-bit floats.\n",
    "\n",
    "When you loop over an array, memory is copied from one location to the next down the list.  Usually you're going to start in RAM, where you generate data or load from disk.\n",
    "\n",
    "Every element in an array has a unique address (in RAM) - for a 64-bit architecture, every address is for a 64-bit (8-byte) word.  This will hold exactly one 64-bit float.\n",
    "\n",
    "Typically, arrays are stored in contiguous blocks of memory, meaning that the first element is stored at some address `a`, the second element is stored at the address `a+1` (64-bits later), and generally the ith element is stored at address `a+i`\n",
    "\n",
    "An array will contain a pointer to the start of the data (i.e. the address of the start of the array), and when you get an element of an array `x[i]`, you first look up the starting address `a`, and then look up the data in address `a+i`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "<memory at 0x7f02ad280940>\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(5)\n",
    "print(x)\n",
    "a = x.data # address of start of array\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note `0x40 = 64`\n",
    "\n",
    "|address|data|\n",
    "|:-:|:-:|\n",
    "|0x00| 0|\n",
    "|0x40| 1|\n",
    "|0x80| 2|\n",
    "|0xb0| 3|\n",
    "\n",
    "When you access some element of memory for a computation in the CPU, you don't just move that one address to cache, but a whole block of memory around that address.  That way when you look at the next address, it is pre-loaded in cache, and you will be able to access the data in that address much faster.  \n",
    "\n",
    "When an address you want to access is not loaded in cache, it is called a **cache miss** and it takes extra time to move that memory to cache and then to the CPU.  Code that minimizes the number of cache misses will be much faster than code that maximizes the number of cache misses.\n",
    "\n",
    "This is why looping over an array in memory order is much faster than looping in a random order.\n",
    "\n",
    "## Two-dimensional arrays\n",
    "\n",
    "Everything we've said so far is fairly straightforward for 1-dimensional arrays.  What about multi-dimensional arrays?\n",
    "\n",
    "We'll consider 2-dimensional arrays, but these ideas generalize to higher dimensions.\n",
    "\n",
    "Two-dimensional arrays have two indices, so at most one of them can be used to access adjacent addresses in memory.  If we store rows (1st index) of a 2-dimensional array in contiguous memory, we say the array is in **row major** format.  If we store columns (2nd index) of a 2-dimensional array in contiguous memory, we say the array is in **column major** format.\n",
    "\n",
    "C/C++ and Python store multi-dimensional arrays in **row major** format\n",
    "\n",
    "Fortran, Matlab, R, and Julia store multi-dimensional arrays in **column major** format\n",
    "\n",
    "Because numerical libraries are often written in C/C++ or Fortran, there will be no end to having to worry about row vs. column major formats in scientific computing.  However, for a variety of reasons column major is considered the default.\n",
    "\n",
    "Numpy supports both row and column major format, but is row-major by default.  You can see this by accessing the `flags` field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  C_CONTIGUOUS : True\n",
       "  F_CONTIGUOUS : False\n",
       "  OWNDATA : True\n",
       "  WRITEABLE : True\n",
       "  ALIGNED : True\n",
       "  WRITEBACKIFCOPY : False\n",
       "  UPDATEIFCOPY : False"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(3,3)\n",
    "x.flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`C_CONTIGUOUS` (C default) is refering to row-major format.  `F_CONTIGUOUS` (fortran default) is referring to column-major.\n",
    "\n",
    "The `order` flag in array creation can be used to manupulate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row major:\n",
      "  C_CONTIGUOUS : True\n",
      "  F_CONTIGUOUS : False\n",
      "  OWNDATA : True\n",
      "  WRITEABLE : True\n",
      "  ALIGNED : True\n",
      "  WRITEBACKIFCOPY : False\n",
      "  UPDATEIFCOPY : False\n",
      "\n",
      "Column major:\n",
      "  C_CONTIGUOUS : False\n",
      "  F_CONTIGUOUS : True\n",
      "  OWNDATA : True\n",
      "  WRITEABLE : True\n",
      "  ALIGNED : True\n",
      "  WRITEBACKIFCOPY : False\n",
      "  UPDATEIFCOPY : False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Row major:\")\n",
    "x = np.array(np.random.rand(3,3), order='C')\n",
    "print(x.flags)\n",
    "\n",
    "print(\"Column major:\")\n",
    "x = np.array(np.random.rand(3,3), order='F')\n",
    "print(x.flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Are 1-dimensional arrays row or column major?  Look at the `flags` field of a numpy array.\n",
    "2. Go back to our example of computing the sum of rows and columns.  Can you explain the timing differences now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling Performance\n",
    "\n",
    "Let's say you have a function that does some computations.  The function runs rather slow, and you'd like to make it run faster.  This function calls two different functions, `f` and `g`.\n",
    "* `f` takes up `90%` of the runtime\n",
    "* `g` takes up `10%` of the runtime\n",
    "\n",
    "Should you focus on optimizing `f` or `g`?\n",
    "\n",
    "How would you find out where most of the time is being spent in a function anyways?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pycourse)",
   "language": "python",
   "name": "pycourse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
